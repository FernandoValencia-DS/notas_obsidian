---
{"dg-publish":true,"permalink":"/keras-y-tensorl-flow/","dgPassFrontmatter":true}
---

Keras es una **biblioteca de alto nivel para el desarrollo de redes neuronales**. Est치 dise침ada para facilitar la construcci칩n, entrenamiento y evaluaci칩n de modelos de Machine Learning, especialmente redes profundas. Este se integra con TensorFlow que es el que se encarga de hacer el procesamiento. En pocas palabras Keras es un puente que le brinda al usuario una codificaci칩n m치s sencilla, luego eso lo lleva a TensorFlow que va a realizar el procesamiento de los datos.

Estas bibliotecas son ampliamente usadas para el desarrollo y entrenamiento de [[Redes Neuronales\|Redes Neuronales]] 

# Funciones

Crea un modelo secuencial, uno de los modelos m치s sencillos, compuesto de una 칰nica pila de capas conectadas de manera secuencial.

*model = keras.models.Sequential()*

A침ade una capa con 300 neuronas y la funci칩n de activaci칩n ReLU, que vimos en [[Redes Neuronales\|Redes Neuronales]]. Nota: Podemos combinar diferentes funciones de activaci칩n en diferentes capas de una red dependiendo del objetivo.

*model.add(keras.layers.Dense(300, activation="relu"))*

## Ejemplo completo

Este ejemplo a침ade las capas una a una con *model.add*
*model = keras.models.Sequential()*
*model.add(keras.layers.Flatten(input_shape=[28, 28]))* 
*model.add(keras.layers.Dense(300, activation="relu"))*
*model.add(keras.layers.Dense(100, activation="relu"))*
*model.add(keras.layers.Dense(10, activation="softmax"))*

Como alternativa podemos incluir todo en un c칩digo 칰nico, as칤:
*model = keras.models.Sequential([ 
	keras.layers.Flatten(input_shape=[28, 28]), keras.layers.Dense(300, activation="relu"), 
	keras.layers.Dense(100, activation="relu"), 
	keras.layers.Dense(10, activation="softmax") 
])*

## Normalizaci칩n 
### Ejemplo: 
```python
# Crear la capa de normalizaci칩n
norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])

# Ajustar la capa con las estad칤sticas de X_train
norm_layer.adapt(X_train)
```
Aqu칤 se defina la capa normalizada por medio de *tf.keras.layers.Normalization*, a esta funci칩n hay que definirle el forma en la que entran los datos (Cuantas caracter칤sticas tiene), para tomar la forma de los datos com칰nmente se toma la forma (.shape) del conjunto de datos, pero a partir de la posici칩n 1, ya que la posici칩n 0 son el numero de filas (instancias).

Adem치s cuando se hace la normalizaci칩n es necesario a침adir el m칠todo  **`adapt()`**  para que capture las estad칤sticas necesarias para la normalizaci칩n (Media y desviaci칩n est치ndar).
# Definici칩n de conjuntos de datos

Es necesario tener conjuntos de **entrenamiento**, **validaci칩n** y **prueba** para garantizar que el modelo aprenda correctamente y su rendimiento sea evaluado de manera adecuada. Cada conjunto cumple un prop칩sito diferente en el desarrollo y evaluaci칩n de un modelo de Machine Learning.

| **Conjunto**      | **Prop칩sito**                                                                               | **Uso en el modelo**                                                                                                |
| ----------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| **Entrenamiento** | Ajustar los par치metros del modelo minimizando la p칠rdida.                                   | El modelo aprende patrones generales en este conjunto.                                                              |
| **Validaci칩n**    | Evaluar el rendimiento mientras se entrena y ajustar hiperpar치metros (no afecta los pesos). | Se eval칰a durante el entrenamiento para decidir cu치ndo detenerse (*early stopping*) o c칩mo ajustar hiperpar치metros. |
| **Prueba**        | Evaluar el rendimiento final del modelo en datos completamente nuevos (nunca usados antes). | Se usa 칰nicamente al final para medir la capacidad de generalizaci칩n a datos del mundo real.                        |
# Compilaci칩n 

En la compilaci칩n indicamos la configura del modelo para el entrenamiento. Esto implica definir los elementos necesarios para que el modelo pueda aprender y ajustarse a los datos. Tiene los siguientes elementos:

## Funci칩n de perdida 

La m칠trica que el modelo usar치 para medir el error entre las predicciones y las etiquetas reales.

Ejemplo: 
-  *Categorical Crossentropy:* cuando tus etiquetas est치n en formato **one-hot encoding**. Cada etiqueta es un vector binario donde solo una posici칩n tiene un valor 1 (indicando la clase verdadera) y las dem치s son 0. ejemplo: Clase 0: [1, 0, 0]
- *Sparse Categorical Crossentropy:* cuando tus etiquetas son **칤ndices enteros** (m치s com칰n porque requiere menos preprocesamiento). Las etiquetas son **칤ndices enteros** que representan directamente la clase. ejemplo: Clase 0: 0

## Optimizador

El optimizador es el algoritmo que ajusta los pesos del modelo durante el entrenamiento para minimizar la p칠rdida.

 - *SGD (Stochastic Gradient Descent):* M칠todo b치sico para el descenso de gradiente

## M칠tricas 

Las m칠tricas se usan para monitorear el rendimiento del modelo. Aunque no afectan el entrenamiento, son 칰tiles para evaluar c칩mo est치 funcionando el modelo en cada 칠poca.

- *accuracy:* Porcentaje de predicciones correctas (en clasificaci칩n).
- *Mae:* Error absoluto promedio (en regresi칩n).

# Modelos

## Regresi칩n

```python
# Crear la capa de normalizaci칩n
norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])

# Ajustar la capa con las estad칤sticas de X_train
norm_layer.adapt(X_train)

# Construir el modelo con la capa ya ajustada
model = tf.keras.Sequential([
    norm_layer,
    tf.keras.layers.Dense(50, activation="relu"),
    tf.keras.layers.Dense(50, activation="relu"),
    tf.keras.layers.Dense(50, activation="relu"),
    tf.keras.layers.Dense(1)
])

# Compilar el modelo
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
model.compile(loss="mse", optimizer=optimizer, metrics=["RootMeanSquaredError"])

# Entrenar el modelo
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))
```

*Nota:* El m칠todo **`adapt()`** es necesario porque la capa de normalizaci칩n (`Normalization`) de Keras necesita calcular las **estad칤sticas** del conjunto de datos (como la **media** y la **desviaci칩n est치ndar**) antes de poder normalizar correctamente las entradas. 

## Tipos de redes

Hasta el momento hemos visto como se estructuran las redes secuenciales, pero hay otro tipo de redes.

# Keras Tuner

Keras Tuner es una herramienta que **busca autom치ticamente los mejores hiperpar치metros** para entrenar un modelo de Keras.

- En lugar de probar manualmente diferentes valores de hiperpar치metros, Keras Tuner **ajusta autom치ticamente** el modelo usando m칠todos como **Grid Search, Random Search o Bayesian Optimization**.

### 游댳 **Ejemplos de hiperpar치metros a ajustar:**

- N칰mero de capas ocultas (`n_hidden`).
- N칰mero de neuronas en cada capa (`n_neurons`).
- Tasa de aprendizaje (`learning_rate`).
- Tipo de optimizador (`optimizer`).